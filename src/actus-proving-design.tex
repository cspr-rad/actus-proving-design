\documentclass[11pt]{article}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[total={7in,9in}]{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage[shortlabels]{enumitem}

\title{Towards a zero knowledge ACTUS proving system}
\author{ \\ Morgan Thomas \\ Casper Association \\ morgan@casper.network }


\begin{document}

\maketitle

This document outlines a general structure for an ACTUS proving system. The goals of such a system are to prove the coherence of term sets and contract states, the correctness of schedules, and the correctness of contract state transitions based on event sequences. The proofs are supposed to be succinct and zero knowledge.

This structure is independent of the specifics of the ACTUS contract type. It is meant to apply to all existing and future ACTUS contract types, as long as some particular fundamentals of the ACTUS information architecture remain the same.

This structure does not assume any particular proving system. It assumes is a zero knowledge virtual machine which can prove the results of executing pure, partial computable functions. Also, it assumes that this zk-VM is capable of recursive proofs.

The scope of this design includes proving facts about individual contracts, and also heterogeneous portfolios of contracts. The cases of individual contracts and portfolios of contracts are addressed within the same structure.

Let $T$ be a set of contract term sets. An element of $T$ describes the terms of zero or more contracts, including any referential relationships between the contracts.

Let $T$ have a lattice structure with a bottom element. This means in other words that there is partial ordering on $T$ such that $T$ is a meet semilattice (every pair of elements has a greatest lower bound), $T$ is a join semilattice (every pair of elements has a least upper bound), and there is an element $\emptyset_T \in T$ such that for all $a \in T$, $\emptyset_T \leq a$.

The idea of this lattice structure is that the join of a pair of elements $t_0, t_1 \in T$ contains all of the contracts in $t_0$ and all of the contracts in $t_1$, whereas the meet of a pair of elements contains all of the contracts that are in both $t_0$ and $t_1$. The bottom element $\emptyset_T$ consists of zero contracts.

To make this lattice structure well defined requires some understanding of the identity conditions of contracts: i.e., when are two contracts the same? It seems to be possible for two contracts to have exactly the same terms, parties, inception date, etc., and to be different only in that they are distinct. Therefore, defining the identity conditions of contracts should rely on assigning a globally unique identifier to each contract. For example, the globally unique identifier of a contract can be a pair of (the unique identifier of) the issuing institution and a serial number. For two contracts to be considered identical, they must have the same globally unique identifier but also the same terms, parties, inception date, etc.

Let $\vee$ denote the join operation of any join semilattice (which join semilattice being specified by context). Let $\wedge$ denote the meet operation of any meet semilattice (which meet semilattice being specified by context).

Let there be a total computable function $\text{coherent} : T \to \{0,1\}$ which outputs $1$ on all and only the coherent term sets, i.e., those term sets satisfying the coherence conditions for term sets of the ACTUS contract types.

Let $E$ be a set of event sequences. An element of $E$ describes zero or more timestamped events which may affect the states of contracts.

Let $I$ be the set of time intervals. An element of $I$ can be described as a closed interval $[t_0, t_1]$, where $t_0, t_1 \in \mathbb{Q}$ are rational numbers and $t_0 \leq t_1$. $t_0$ and $t_1$ represent Unix timestamps, i.e., seconds since the Unix epoch. Observe that $I$ is a meet semilattice under the following partial ordering:

\begin{equation}
	[t_0,t_1] \leq [t_2,t_3] \Leftrightarrow (t_0 \leq t_2 \vee t_1 \leq t_3).
\end{equation}

Let $\leqslant$ be the partial ordering on $I$ defined as follows:

\begin{equation}
	[t_0,t_1] \leqslant [t_2,t_3] \Leftrightarrow t_1 < t_2.
\end{equation}

Let there be a total computable function $\text{range} : E \to I$ which gives the time interval of an event sequence, i.e., the range of timestamps of events in the sequence.

Let there be a partial computable function $\smallfrown\ : E \times E \to E$ which joins compatible event sequences. An ordered pair $(e_0, e_1)$ of event sequences is compatible if and only if $\text{range}(e_0) \leqslant \text{range}(e_1)$. $\smallfrown$ is defined on all and only the compatible pairs of event sequences. The function $\smallfrown$ should output the concatenation of the two input event sequences. This requires that:

\begin{equation}
	\text{range}(e_0 \smallfrown e_1) = \text{range}(e_0) \vee \text{range}(e_1).
\end{equation}

Let $C$ be a set of contract states. An element of $C$ represents the states of all contracts in an element of $T$, at some point in time. 

Let there be a total computable function $\text{asOf} : C \to \mathbb{Q}$ which gives the Unix timestamp which a state $c \in C$ is as of.

Let there be a partial computable function $\text{initial} : T \to C$, giving the initial states of all contracts in an element of $T$. initial should be defined on all and only the coherent elements of $T$, i.e., those $t \in T$ such that $\text{coherent}(t) = 1$.

Let there be a total computable function $\text{applies} : T \times C \to \{0,1\}$, which outputs 1 on an input pair $(t, c)$ if and only if $c$ makes sense as a description of the states of the contracts in $t$, meaning that $c$ describes the states of all of the contracts in $t$ and no other contracts.

Let $\pi_0 : A \times B \to A$ and $\pi_1 : A \times B \to B$ be the generic Cartesian product projection functions.

Let there be a partial computable function $\text{update} : T \times C \times E \to C$, the state transition function. This function takes as input a term set $t \in T$, a state $c \in C$, and an event sequence $e \in E$. This function is defined on an input triple $(t, c, e)$ if and only if $\text{asOf}(c) < \pi_0(\text{range}(e))$, $\text{coherent}(t) = 1$, and $\text{applies}(t, c) = 1$.

Let there be a partial computable function $\oplus\ : C \times C \to C$. This function serves to combine simultaneous states for disjoint sets of contracts. This can always be done without conflict. $c_0 \oplus c_1$ is defined if and only if there are $t_0, t_1, \in T$ such that: $\text{applies}(t_0, c_0) = 1$, $\text{applies}(t_1, c_1) = 1$, $t_0 \wedge t_1 = \emptyset_T$, and $\text{asOf}(c_0) = \text{asOf}(c_1)$. If $c_0 \oplus c_1$ is defined, then the $t_0, t_1 \in T$ witnessing this fact are unique (because each state can apply only to one set of contracts).

The following laws should be true:

\begin{enumerate}
	\item If $\text{update}(t, c, e)$ is defined, then $\text{applies}(t, \text{update}(t, c, e)) = 1$ and:
		\begin{equation}
			\text{asOf}(\text{update}(t, c, e)) = \pi_1(\text{range}(e)).
		\end{equation}
	\item If $\text{update}(t, c, e_0)$ and $\text{update}(t, \text{update}(t, c, e_0), e_1)$ are defined, and $e_0 \smallfrown e_1$ is defined, then
		\begin{equation}
			\text{update}(t, c, e_0 \smallfrown e_1) = \text{update}(t, \text{update}(t, c, e_0), e_1).
		\end{equation}
	\item If $\text{coherent}(t) = 1$, then $\text{applies}(t, \text{initial}(t)) = 1$.
	\item If $c_0 \oplus c_1$ is defined, then $\text{asOf}(c_0 \oplus c_1) = \text{asOf}(c_0)$, and for the unique $t_0, t_1 \in T$ such that $\text{applies}(t_0, c_0) = 1$ and $\text{applies}(t_1, t_1) = 1$,
		\begin{equation}
			\text{applies}(t_0 \vee _1, c_0 \oplus c_1) = 1.
		\end{equation}
	\item If $\text{applies}(t_0, c_0) = 1$, and $\text{applies}(t_1, c_1) = 1$, and $t_0 \wedge t_1 = \emptyset_T$, and $\text{asOf}(c_0) = \text{asOf}(c_1)$, and $\text{update}(t_0, c_0, e)$ and $\text{update}(t_1, c_1, e)$ are defined, then:
		\begin{equation}
			\text{update}(t_0 \vee t_1, c_0 \oplus c_1, e) = \text{update}(t_0, c_0, e) \oplus \text{update}(t_1, c_1, e).
		\end{equation}
\end{enumerate}

The laws ensure that the state transitions have the same results regardless of how finely we slice an event sequence and how many times we apply the update function. They also ensure that the state transitions have the same results when they act on portfolios as when they act on slices of those portfolios, up to and including individual contracts within those portfolios.

Let there be a partial computable function $\text{schedule} : T \times C \to E$. This function takes a pair $(t, c)$ of contracts and states. It returns a canonical event sequence which would fulfill all of the contracts $t$ starting from states $c$. $\text{schedule}(t, c)$ is defined if and only if $\text{applies}(t, c) = 1$.

Let $H$ be a collision-resistant, 256-bit hash function. When we apply $H$ to an object, let it denote the result of Merkelizing the object, i.e., transforming the object into the root of a Merkle hash tree using the hash function $H$. This process should allow each piece of the object being serialized to be verified using a Merkle opening proof.

There can be more than one valid way of Merkelizing an object. Consider for example an event sequence $e = e_0 \smallfrown e_1 \smallfrown e_2 \smallfrown e_3$. This could be Merkelized as $H((H(e_0 \smallfrown e_1), H(e_2 \smallfrown e_3)))$, or alternately as $H((H(e_0), H(e_1 \smallfrown e_2 \smallfrown e_3)))$, or $H((H((H(e_0), H(e_1))), H((H(e_2), H(e_3)))))$. These are just a few of the alternatives. The reason for allowing such flexibility is to provide degrees of freedom in how recursive proofs (which are about to be described) may be composed. The end result is that there is not a unique valid hash for a given object, which is ultimately okay.

The ZK proving system requires some primitives for recursively proving facts about sets and sequences. Specifically, we need to be able to prove facts of the following forms:

\begin{enumerate}
	\item For sets $A, B, C$, $A \cup B = C$.
	\item For sets $A, B$, $A \cap B = \emptyset$.
	\item For sets $A, B$ and partial computable functions $f$, $f(A) = B$.\footnote{$f(A)$ denotes the image of the set $A$ under the function $f$, i.e., $\{f(a) | a \in A\}$.}
	\item For sequences $e, e_0, e_1$, $e = e_0 \smallfrown e_1$.
\end{enumerate}

The motivation for being able to recursively prove such facts is to be able to deal with sets and sequences that are larger than what we can deal with directly in a single proof. In particular, we wish to prove statements of the following forms:

\begin{enumerate}
	\item For hashes $h, h_0, h_1$, there are sets $A, B, C$ such that $A \cup B = C$, $H(C) = h$, $H(A) = h_0$, and $H(B) = h_1$.
	\item For hashes $h_0, h_1$, there are sets $A, B$ such that $A \cap B = \emptyset$, $H(A) = h_0$, and $H(B) = h_1$.
	\item For hashes $h_0, h_1$, there are sets $A, B$ such that $f(A) = B$, $h(A) = h_0$, and $h(B) = h_1$. (This statement form is for a fixed function $f$.)
	\item For hashes $h, h_0, h_1$, there are sequences $e, e_0, e_1$ such that $e = e_0 \smallfrown e_1$, $H(e) = h$, $H(e_0) = h_0$, and $H(e_1) = h_1$.
\end{enumerate}

For each of these statements forms, there is an applicable recursive proof scheme. For each recursive proof scheme, a proof may be either a leaf or a branch proof. A leaf proof proves a statement of the specified form by proving the execution of a computation which directly verifies the statement. A branch proof verifies two or more ZK proofs of the same scheme, and verifies that the statements those inner proofs prove suffice for the truth of the statement it verifies.

Let $\uplus$ be a partial computable function of two sets and a set element, defined as follows. For interpreting applications of $\uplus$, there is implied to be a total ordering relation which applies to set elements. An application of $\uplus$ will be denoted by $A \uplus_x B$, where $A, B$ are the sets and $x$ is the set element. $x$ is called the pivot element. $A \uplus_x B$ is equal to $A \cup B$, if and only if $a \leq x$ for all $a \in A$ and $x < b$ for all $b \in B$. Otherwise, $A \uplus_x B$ is undefined.

Here is a description of the branch proofs in the set union recursive proving scheme. Suppose for given hashes $h, h_0, h_1$, we want to show there are sets $A, B, C$ such that $A \cup B = C$, $H(C) = h$, $H(A) = h_0$, and $H(B) = h_1$. We do so by proving that there are sets $A_0, A_1, B_0, B_1, C_0, C_1$ and a set element $x$ such that:
\begin{enumerate}
	\item $A_0 \uplus_x A_1 = A$.
	\item $B_0 \uplus_x B_1 = B$.
	\item $C_0 \uplus_x C_1 = C$.
	\item $A_0 \cup B_0 = C_0$.
	\item $A_1 \cup B_1 = C_1$.
\end{enumerate}
These facts suffice to imply that $A \cup B = C$. If $A \cup B = C$ and $A, B, C$ are nonempty, then such a set of facts can be constructed, and doing so suffices to reduce the problem of proving $A \cup B = C$ to two smaller set union proving problems. Those smaller set union proving problems can be proven in ZK and their proofs verified recursively.

This proving scheme for set unions requires a system for succinctly verifying facts of the form $A \uplus_x B = C$. Specifically, this can be done by succinctly verifying statements of the form: for given $h, h_0, h_1, h_x$, there are sets $A, B, C$ and a set element $x$ such that $A \uplus_x B = C$, $H(A) = h_0$, $H(B) = h_1$, $H(C) = h$, and $H(x) = h_x$. Such a statement can be verified in $O(1)$ when sets are Merkelized, because it just requires that $h$ be the root of a Merkelization of $C$ which decomposes $C$ into $A \setminus \{x\}, \{x\}$, and $B$. It should be denoted that this proving scheme does require that we can choose $h$ to be whatever the root of whatever Merkelization of $C$ makes this proving scheme work.

TODO: set disjointness; set image; sequence concatenation

The ZK proving system needs to prove statements of the following forms. For each of these forms, the instance data consists of the hash $h$.

\begin{enumerate}
	\item There is a $t \in T$ such that $H(t) = h$ and $\text{coherent}(t) = 1$.
	\item There is $x \in T \times C$ such that $H(x) = h$ and $\text{applies}(t, c) = 1$.
	\item There is $x = (t, c, s) \in T \times C \times E$ such that $H(x) = h$ and $\text{schedule}(t, c) = s$.
	\item There is $x = (t, c_0, e, c_1) \in T \times C \times E \times C$ such that $H(x) = h$ and $\text{update}(t, c_0, e) = c_1$.
\end{enumerate}

For each of these statement forms, there is an applicable recursive proof scheme. The reason for the proof schemes being recursive is that we assume that there is an upper bound on the amount of computation we can verify in a single proof, but we require the system to scale to function executions on arbitrarily complex inputs. For each recursive proof scheme, a proof may be either a leaf or a branch proof. A leaf proof proves a statement of the specified form by directly proving the evaluation of the function on the given input. A branch proof verifies two or more ZK proofs of the same scheme, and verifies that the statements those inner proofs prove suffice for the truth of the statement it verifies.

Although branch proofs are described below with exactly two children, the descriptions can be extended in a straightforward manner to allow for branching factors greater than two.

A branch proof of $\text{coherent}(t) = 1$ verifies that there are some $t_0, t_1 \in T$ such that $t_0 \vee t_1 = t$, $\text{coherent}(t_0) = 1$, and $\text{coherent}(t_1) = 1$. The instance data in this case is $H((h_0, h_1))$, where $h_i$ is the Merkelization of $t_i$. TODO: it also needs to verify that contract identifiers are globally unique, which implies that $t_0, t_1$ are disjoint

A branch proof of $\text{applies}(t, c) = 1$ verifies that there are some $t_0, t_1 \in T$ and $c_0, c_1 \in C$ such that $t_0 \vee t_1 = t$ and $c_0 \oplus c_1 = c$, such that $\text{applies}(t_0, c_0) = 1$, and $\text{applies}(t_1, c_1) = 1$. The instance data in this case is $H((h_0, h_1))$, where $h_i$ is the Merkelization of $(t_i, c_i)$. TODO: also needs to verify that $t_0, t_1$ are disjoint

TODO: schedule branch proofs; need to define regularity in schedules to make this possible

A \emph{vertically sliced}\/ branch proof of $\text{update}(t, c_0, e) = c_1$ verifies that there are some $t_0, t_1 \in T$ and $c_{0,0}, c_{0,1}, c_{1,0}, c_{1,1} \in C$ such that $t_0 \vee t_1 = t$ and $c_{0,0} \oplus c_{0,1} = c_0$ and $c_{1,0} \oplus c_{1,1} = c_1$ and $\text{update}(t_0, c_{0,0}, e) = c_{1,0}$ and $\text{update}(t_1, c_{0,1}, e) = c_{1,1}$. The instance data in this case is $H((h_0, h_1))$, where $h_i$ is the Merkelization of $(t_i, c_{0,i}, e, c_{1,i})$. TODO: also needs to verify that $t_0, t_1$ are disjoint

A \emph{horizontally sliced}\/ branch proof of $\text{update}(t, c_0, e) = c_2$ verifies that there are some $e_0, e_1 \in E$ and $c_1 \in C$ such that $e = e_0 \smallfrown e_1$, and $\text{update}(t, c_0, e_0) = c_1$, and $\text{update}(t, c_1, e_1) = c_2$. The instance data in this case is $H((h_0, h_1))$, where $h_i$ is the Merkelization of $(t, c_i, e_i, c_{1+i})$. TODO: how to prove event sequence concatenation?

\end{document}
